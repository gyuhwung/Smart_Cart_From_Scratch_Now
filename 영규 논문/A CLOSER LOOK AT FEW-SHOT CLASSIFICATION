https://underdogy.tistory.com/1

1. 논문 요약

 

해당 논문은 ICLR 2019에서 발표된 퓨샷러닝(few shot learning, few shot classification) 분야의 논문으로 자신들이 개발한 베이스라인 모델과 함께 현재까지 뛰어난 기술이라고 평가받는 모델들을 비교하는 내용이다. 이러한 비교연구를 통해 다양한 시사점들을 제시하고 있다.

 

주요 시사점

- 깊은 구조의 모델(deep backbone)일수록 새로운 데이터에 적용할 때의 성능 차이를 줄여준다.

- 단순해 보이는 베이스라인 모델이 결코 성능이 떨어지는 것이 아니다. 오히려 더 뛰어난 경우도 있다.

   (복잡하고 어려운 최신 기술을 도입한 모델이 최선이 아니다. occam's razor가 떠오르는..)

- few shot learning 테스크에서는 클래스 내의 분산을 줄이는 것이 매우 중요하다.

- 네트워크 깊이가 깊어질 수록 클래스 내 분산이 줄어들어 성능이 좋아진다.

 

2. 배경지식

 

2.1 few shot learning 이란?


dog 사진 3개, cat 사진 3개
few shot learning은 극히 제한적인 양의 train data를 가지고 학습을 시켜 모델을 만드는 것이다. 

위 그림과 같이, 강아지와 고양이의 사진 데이터를 학습하여 분류하는 모델을 만든다고 했을 때 각 3장씩의 사진은 모델을 구축하기에는 매우 적은 양의 데이터일 것이다. 해당 문제를 few shot learning이라고 하며, '2-way 3-shot 문제' (2개의 class, 각 class당 3개의 사진)라고 표현한다.

데이터가 적을 경우 Augmentation(기존 데이터로부터 가상의 새로운 비슷한 데이터 만들기) 방법이 있지만, 해당 논문은 모델 비교이기 때문에 일단 제외하도록 하고, 해당 문제를 풀기위해 현재까지 어떤 연구와 모델링이 진행되었는지는 논문에 자세히 나와있기 때문에 논문과 함께 설명한다.

 

 

3. 논문 살펴보기

 

논문에서는 다양한 모델을 비교하기 위해 어떤 모델들이 있는지 설명하고 있다.

이후 모델의 성능을 비교한다.

현재 few shot learning 분야는 크게 3가지의 기술로 분류된다.

 

3.1 few shot learning 모델 분류

1) Initialization based methods

기존에 이미지 인식 및 분류에 뛰어나다고 평가된 모델을 새로운 데이터를 적용하여 파인 튜닝해서 사용하는 것. 가령 기구축된 모델의 파라미터를 튜닝하거나, 옵티마이저를 변경한다거나 가중치 업데이트 방식을 변경한다거나 하는 방법이다.

2) Distance metric learning based methods

데이터를 분류한다는 것은 가장 거리가 가까운(유사한, 유사도가 높은) 데이터를 찾는 것이 기본 접근 방법론으로, 가령 새로운 이미지를 어떻게 분류할 것인가는 가장 가까운 데이터를 찾아 해당 데이터의 class로 분류하는 것이라고 볼 수 있다. 거리 기반이기 때문에 어떤 거리 산출방식을 사용할 것인가에 성능이 크게 달라지며, cosine similarity를 사용하는 MatchingNet, Euclidean distance를 사용하는 ProtoNet 등이 있다.

3) Hallucination based methods

data augmentation에 가장 가까운 방법으로, 기존 데이터로부터 개발된 generator(GAN 등) 모델 자체와 해당 모델을 새로운 데이터에 적용하기 위해 transferring하는 기술들이 여기에 포함된다.

 

정확하게 3개 형태로 분류되진 않는다. 현재 다양한 최신모델들이 Domain Adaptaion 기술을 포함하여 위 기술들을 복합적으로 활용한다.

 

3.2 각 모델 구조

1) BASELINE, BASELINE++

다양한 모델을 비교하기 위한 기본 모델로 여기서는 baseline, baseline++ 모델을 제시하고 있다.


Figure1 : baseline 과 baseline++ 모델 구조
우선 baseline 모델은 단순하다. extractor network에 linear layer, sofrtmax layer가 연결되어 분류하는 형태다.

baseline++ 모델은 기존 baseline에서 사용된 구조를 동일하게 가져가나 classifier에서 linear layer를 cosine distance로 바꿔 새로운 데이터를 적용해 fine tunning한 형태이다. 이 cosine distance를 사용한다는 것은 내용적으로는 다른 것이 새로운 데이터가 들어왔을때 각 class와의 cosine distance를 계산하여 class 내의 분산을 감소시키는 방향으로 학습 튜닝이 된다는 점이다.

 


baseline++모델이 튜닝되는 과정은 위와 같다. x라는 데이터가 들어왔을 때 fθ extractor를 거쳐 값이 나오게 되면, 각 클래스에 해당하는 웨이트 벡터와 코사인 유사도를 계산한다. 이 후 계산된 유사도 값은 softmax를 거쳐 0~1사이의 확률값으로 변환된 후 클래스를 분류하는 방식이다. (아래 논문 설명)

 


 

2) META-LEARNING ALGORITHMS


META-LEARNING 모델 구조
메타 러닝 방식은 클래스를 나누어 첫번째 클래스 집합으로 트레이닝, 첫번째 클래스 집합에 없는 클래스로 구성된 두번째 클래스 집합으로 테스트하여 일반화 성능을 높이는 방법이다. 각 클래스 집합은 support set과 query set으로 나눠 support set 기반으로 구축된 모델을 query set과 유사도를 기반으로 loss를 줄이는 방식으로 모델이 만들어 진다. 대표적으로 MatchingNet은 모델이 cosine distance를 활용하고 있는데 baseline++모델과 유사할 수 있는데 다른 점은, baseline++모델은 초기에 baseline에서 학습된 웨이트를 시작으로 cosine distance를 계산한다는 점, meta learning은 데이터를 샘플링한점, Support set과 query set으로 나눈다는 점이 큰 차이점이다.

 

3.3 모델 성능 비교


여러 모델은 모두 동일하게 conv 4layers backbone의 구조를 가지고 있으며 CUB, mini-ImageNet 데이터셋에서 1shot, 5shot 기준으로 성능을 비교한 표이다. 주목할 점은 baseline++ 모델이 MatchingNet~RelationNet까지의 최신 기술에 뒤쳐지지 않는다는 점이다. (오히려 5shot에서는 성능이 더 뛰어나는 경우도 존재)

저자는 이런 baseline으로 만든 모델들이 매우 저평가되어 있다고 한다.

 

3.3 네트워크 깊이가 깊을 수록 좋은가?


네트워크 깊이를 달리했을 때에도 baseline++ 모델은 다른 메타러닝 모델들에 비해 성능이 뒤쳐지지 않는다.

네트워크 깊이가 깊어질 수록 클래스 내 분산이 줄어들어 성능이 좋아진다.

 

3.3 도메인이 다르다면 모델의 성능은 어떻게 되는가?

 

새로운 데이터가 도메인이 다르다면 성능이 떨어지는 것은 당연하다.(개, 고양이 즉 동물을 분류하는 모델을 만들었는데 음식을 분류하는 테스크 이미지가 들어왓을 경우). 이건 메타러닝에서는 특히 중요한 문제로 너무 다른 도메인의 데이터가 들어왔을 경우, support set을 기반으로 구축되기 때문에 새로운 데이터셋에 적응하기는 쉽지 않기 때문이다. 저자는 meta learning에서 데이터 adaptation 문제를 나아가야할 방향 및 과제로 남긴다.

 

4. 결론

단순한 baseline, baseline++ 모델도 상당히 경쟁력있는 모델이라는 것이라는 점이 가장 크며, 다양한 few shot learning 알고리즘을 비교하는 방법들을 소개하고 시사점을 도출했다는 점이 논문의 주요 내용이다.
